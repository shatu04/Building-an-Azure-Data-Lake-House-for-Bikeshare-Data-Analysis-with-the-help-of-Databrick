# 🚲 Azure Data Lakehouse for Bikeshare Data Analysis

This project showcases how to build a scalable **Azure Data Lakehouse** solution using **Databricks** to analyze bikeshare data efficiently.

---

## 🧱 Architecture Overview

- **Azure Data Lake Storage Gen2** – Stores raw and processed data
- **Azure Databricks** – Used for data engineering and analysis
- **PySpark** – For data transformation and querying
- **Notebook** – Contains the entire pipeline logic
  

---

## 📁 Project Structure

Files_Databrick And Schema.zip
├── Files_Databrick.html # Databricks notebook (exported HTML)
├── Schema.docx # Dataset schema documentation
├── all output screenshoot.docx # Output visual screenshots


---

## 🔧 How to Use

1. Open Databricks → Import the notebook from the `.html` file (or re-create manually).
2. Set up Azure Data Lake Gen2 storage and upload your bikeshare dataset.
3. Run the ETL code inside Databricks.
4. Visualize or export the results.

---

## 📝 Data Schema

Details can be found in `Schema.docx`, which includes:
- Column names
- Data types
- Description of each field

---

## 📊 Screenshots

See `all output screenshoot.docx` for sample results and visual validation.

---

## 📦 Technologies Used

- Azure Databricks
- Azure Data Lake Storage Gen2
- PySpark (inside Databricks)
- Python
- Excel (optional visualization)

---

## 🙌 Acknowledgements

Inspired by public bikeshare datasets and Azure architecture blueprints.
