# ğŸš² Azure Data Lakehouse for Bikeshare Data Analysis

This project showcases how to build a scalable **Azure Data Lakehouse** solution using **Databricks** to analyze bikeshare data efficiently.

---

## ğŸ§± Architecture Overview

- **Azure Data Lake Storage Gen2** â€“ Stores raw and processed data
- **Azure Databricks** â€“ Used for data engineering and analysis
- **PySpark** â€“ For data transformation and querying
- **Notebook** â€“ Contains the entire pipeline logic
  

---

## ğŸ“ Project Structure

Files_Databrick And Schema.zip
â”œâ”€â”€ Files_Databrick.html # Databricks notebook (exported HTML)
â”œâ”€â”€ Schema.docx # Dataset schema documentation
â”œâ”€â”€ all output screenshoot.docx # Output visual screenshots


---

## ğŸ”§ How to Use

1. Open Databricks â†’ Import the notebook from the `.html` file (or re-create manually).
2. Set up Azure Data Lake Gen2 storage and upload your bikeshare dataset.
3. Run the ETL code inside Databricks.
4. Visualize or export the results.

---

## ğŸ“ Data Schema

Details can be found in `Schema.docx`, which includes:
- Column names
- Data types
- Description of each field

---

## ğŸ“Š Screenshots

See `all output screenshoot.docx` for sample results and visual validation.

---

## ğŸ“¦ Technologies Used

- Azure Databricks
- Azure Data Lake Storage Gen2
- PySpark (inside Databricks)
- Python
- Excel (optional visualization)

---

## ğŸ™Œ Acknowledgements

Inspired by public bikeshare datasets and Azure architecture blueprints.
